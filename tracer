#!/usr/bin/env python

import pdb

##############################################################################
# TraCeR - a tool to reconstruct TCR sequences from single-cell RNA-seq data #
#                      EDIT tracer.conf BEFORE USE!                          #
#                                                                            #
# Please see README and LICENCE for details of use and licence conditions.   #
# This software was written by Mike Stubbington (mstubb@ebi.ac.uk) from the  #
# Teichmann Lab, EMBL-EBI (www.teichlab.org). Latest versions are available  #
# for download at www.github.com/teichlab/tracer.                            #
#                                                                            #
#      Copyright (c) 2015 EMBL - European Bioinformatics Institute           #
##############################################################################


import matplotlib as mpl
mpl.use('pdf')
import seaborn as sns
from matplotlib import pyplot as plt
import tracer_func as tracer
import ConfigParser
import argparse
import sys
import os
import subprocess
import pipes
import glob
import shutil
import re
from collections import defaultdict, Counter
from time import sleep
import warnings
import pickle
from prettytable import PrettyTable


class Launcher():
    def __init__(self):
        parser = argparse.ArgumentParser(description='TraCeR: reconstruction of TCR sequences from single-cell RNAseq data', usage = ''' tracer <mode> [<args>]

        Modes are :

        - assemble: assemble TCR sequences from single-cell RNA-sequencing reads
        - summarise: summarise TCR sequences from set of cells, build clonotype networks

        use tracer <mode> -h for specific help
        ''')
        parser.add_argument('mode', metavar="<MODE>", help='tracer mode (assemble, build or summarise)', choices = ['assemble', 'build_synth_genome', 'summarise', 'summarize', 'build_igblast_index'])
        args = parser.parse_args(sys.argv[1:2])

        if not hasattr(self, args.mode):
            print 'Unrecognised mode'
            parser.print_help()
            exit(1)



        getattr(self, args.mode)()







    ##ASSEMBLE
    def assemble(self):
        parser = argparse.ArgumentParser(description = "Reconstruct TCR sequences from RNAseq reads for a single cell")
        parser.add_argument('--ncores', '-p', metavar="<CORES>", help='number of processor cores to use', type=int, default=1)
        parser.add_argument('--config_file', '-c', metavar="<CONFIG_FILE>", help='config file to use [tracer.conf]', default='tracer.conf')
        parser.add_argument('--resume_with_existing_files', '-r', help='look for existing intermediate files and use those instead of starting from scratch', action="store_true")
        parser.add_argument('--species', '-s', help='species from which T cells were isolated - important to determination of iNKT cells', choices=['Mmus', 'Hsap'], default='Mmus')
        parser.add_argument('fastq1', metavar="<FASTQ1>", help='first fastq file')
        parser.add_argument('fastq2', metavar="<FASTQ2>", help='second fastq file')
        parser.add_argument('cell_name', metavar="<CELL_NAME>", help='name of cell for file labels')
        parser.add_argument('output_dir', metavar="<OUTPUT_DIR>", help='directory for output as <output_dir>/<cell_name>')
        args = parser.parse_args(sys.argv[2:])

        cell_name = args.cell_name
        fastq1 = args.fastq1
        fastq2 = args.fastq2
        ncores = str(args.ncores)

        #Read config file
        config = ConfigParser.ConfigParser()
        config.read(args.config_file)

        bowtie2 = self.resolve_relative_path(config.get('tool_locations', 'bowtie2_path'))
        igblast = self.resolve_relative_path(config.get('tool_locations', 'igblast_path'))
        kallisto = self.resolve_relative_path(config.get('tool_locations', 'kallisto_path'))
        trinity = self.resolve_relative_path(config.get('tool_locations', 'trinity_path'))

        if config.has_option('trinity_options', 'trinity_grid_conf'):
            trinity_grid_conf = self.resolve_relative_path(config.get('trinity_options', 'trinity_grid_conf'))
        else:
            trinity_grid_conf = False


        synthetic_genome_path = self.resolve_relative_path(config.get('bowtie2_options', 'synthetic_genome_index_path'))
        igblast_index_location = self.resolve_relative_path(config.get('IgBlast_options', 'igblast_index_location'))
        igblast_seqtype = config.get('IgBlast_options', 'igblast_seqtype')
        imgt_seq_location = self.resolve_relative_path(config.get('IgBlast_options', 'imgt_seq_location'))

        kallisto_base_transcriptome = self.resolve_relative_path(config.get('kallisto_options', 'base_transcriptome'))

        #check that executables from config file can be used
        not_executable = []
        for name, x in {"bowtie2":bowtie2, "igblast":igblast, "kallisto":kallisto, "trinity":trinity}.iteritems():
            if not tracer.is_exe(x):
                not_executable.append((name, x))
        if len(not_executable) > 0:
            print
            print "Could not execute the following required tools. Check your configuration file."
            for t in not_executable:
                print t[0], t[1]
            print
            exit(1)


        #set-up output directories
        root_output_dir = os.path.abspath(args.output_dir)
        tracer.makeOutputDir(root_output_dir)
        output_dir = root_output_dir + "/" + cell_name

        tracer.makeOutputDir(output_dir)

        data_dirs = ['aligned_reads','Trinity_output', 'IgBLAST_output', 'unfiltered_TCR_seqs', 'expression_quantification', 'filtered_TCR_seqs']
        for d in data_dirs:
            tracer.makeOutputDir("{}/{}".format(output_dir, d))

        locus_names = ["TCRA", "TCRB"]

        should_resume = args.resume_with_existing_files

        self.bowtie2_alignment(bowtie2, ncores, locus_names, output_dir, cell_name, synthetic_genome_path, fastq1, fastq2, should_resume)
        print
        trinity_JM = config.get('trinity_options', 'max_jellyfish_memory')
        self.assemble_with_trinity(trinity, locus_names, output_dir, cell_name, ncores, trinity_grid_conf, trinity_JM, should_resume, args.species)
        print
        self.run_IgBlast(igblast, locus_names, output_dir, cell_name, igblast_index_location, igblast_seqtype, should_resume)
        print

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            cell = tracer.parse_IgBLAST(locus_names, output_dir, cell_name, imgt_seq_location, args.species)

        self.quantify_with_kallisto(kallisto, cell, output_dir, cell_name, kallisto_base_transcriptome, fastq1, fastq2, ncores, should_resume)

        print

        counts = tracer.load_kallisto_counts("{}/expression_quantification/abundance.tsv".format(output_dir))

        for locus, recombinants in cell.all_recombinants.iteritems():
            if recombinants is not None:
                for rec in recombinants:
                    if rec.contig_name in counts[locus]:
                        tpm = counts[locus][rec.contig_name]
                    else:
                        print >> sys.stderr, "WARNING: count data NOT FOUND for %s " % rec.contig_name
                        tpm=0
                    rec.TPM = tpm

        self.print_cell_summary(cell, "{output_dir}/unfiltered_TCR_seqs/unfiltered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/unfiltered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))
        print "##Filtering by read count##"
        cell.filter_recombinants()
        fasta_filename = "{output_dir}/filtered_TCR_seqs/{cell_name}_TCRseqs.fa".format(output_dir=output_dir, cell_name=cell_name)
        fasta_file = open(fasta_filename, 'w')
        fasta_file.write(cell.get_fasta_string())
        fasta_file.close()
        self.print_cell_summary(cell, "{output_dir}/filtered_TCR_seqs/filtered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/filtered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))


    def resolve_relative_path(self, path):
        if not path.startswith("/"):
            base_directory = os.path.abspath(os.path.dirname(__file__))
            full_path = os.path.normpath("{}/{}".format(base_directory, path))
        else:
            full_path = path
        return full_path

    def bowtie2_alignment(self, bowtie2, ncores, locus_names, output_dir, cell_name, synthetic_genome_path, fastq1, fastq2, should_resume):
        print "##Finding TCR-derived reads##"

        if should_resume:
            for locus in locus_names:
                aligned_read_path = "{}/aligned_reads/{}_{}_".format(output_dir, cell_name, locus)
                fastq1_out= "{}1.fastq".format(aligned_read_path)
                fastq2_out= "{}2.fastq".format(aligned_read_path)
                if os.path.isfile(fastq1_out) and os.path.isfile(fastq2_out):
                    print "Resuming with existing TCRA and B reads"
                    return

        for locus in locus_names:
            print "##{}##".format(locus)
            sam_file = "{}/aligned_reads/{}_{}.sam".format(output_dir, cell_name, locus)
            aligned_read_path = "{}/aligned_reads/{}_{}_%.fastq".format(output_dir, cell_name, locus)
            command = [bowtie2, '--no-unal', '-p', ncores, '-k', '1', '--np', '0', '--rdg', '1,1', '--rfg', '1,1', '-x', "/".join([synthetic_genome_path, locus]), '-1', fastq1, '-2', fastq2, '--al-conc', aligned_read_path, '-S', sam_file]


            subprocess.check_call(command)





    def assemble_with_trinity(self, trinity, locus_names, output_dir, cell_name, ncores, trinity_grid_conf, JM, should_resume, species):
        print  "##Assembling Trinity Contigs##"

        if should_resume:
            trinity_report_successful =  "{}/Trinity_output/successful_trinity_assemblies.txt".format(output_dir)
            trinity_report_unsuccessful = "{}/Trinity_output/unsuccessful_trinity_assemblies.txt".format(output_dir)
            if (os.path.isfile(trinity_report_successful) and os.path.isfile(trinity_report_unsuccessful)) and (os.path.getsize(trinity_report_successful) >0 or os.path.getsize(trinity_report_unsuccessful) >0) :
                print "Resuming with existing Trinity output"
                return


        command = [trinity]
        if trinity_grid_conf:
            command = command + ['--grid_conf', trinity_grid_conf]

        command = command + ['--JM', JM, '--seqType', 'fq', '--CPU', ncores, '--full_cleanup']

        for locus in locus_names:
            print "##{}##".format(locus)
            trinity_output = "{}/Trinity_output/{}_{}".format(output_dir, cell_name, locus)
            aligned_read_path = "{}/aligned_reads/{}_{}_".format(output_dir, cell_name, locus)
            file1 = "{}1.fastq".format(aligned_read_path)
            file2 = "{}2.fastq".format(aligned_read_path)
            command = command + ["--left", file1, "--right", file2, "--output", '{}'.format(trinity_output)]
            try:
                subprocess.check_call(command)
            except subprocess.CalledProcessError:
                print "Trinity failed for locus"

        #clean up unsuccessful assemblies
        sleep(10) #this gives the cluster filesystem time to catch up and stops weird things happening
        successful_files = glob.glob("{}/Trinity_output/*.fasta".format(output_dir))
        unsuccessful_directories = os.walk("{}/Trinity_output".format(output_dir)).next()[1]
        for directory in unsuccessful_directories:
            shutil.rmtree("{}/Trinity_output/{}".format(output_dir, directory))
        successful_file_summary = "{}/Trinity_output/successful_trinity_assemblies.txt".format(output_dir)
        unsuccessful_file_summary = "{}/Trinity_output/unsuccessful_trinity_assemblies.txt".format(output_dir)

        successful_files = tracer.clean_file_list(successful_files)
        unsuccessful_directories = tracer.clean_file_list(unsuccessful_directories)


        success_out = open(successful_file_summary, "w")
        fail_out = open(unsuccessful_file_summary, "w")

        successful = defaultdict(list)
        unsuccessful = defaultdict(list)

        successful_ordered_files = set()
        unsuccessful_ordered_files = set()

        for filename in successful_files:
            #success_out.write("{}\n".format(filename))
            parsed_name = tracer.get_filename_and_locus(filename)
            successful[parsed_name[0]].append(parsed_name[1])
            successful_ordered_files.add(parsed_name[0])
        successful_ordered_files = sorted(list(successful_ordered_files))


        for filename in unsuccessful_directories:
            #fail_out.write("{}\n".format(filename))
            parsed_name = tracer.get_filename_and_locus(filename)
            unsuccessful[parsed_name[0]].append(parsed_name[1])
            unsuccessful_ordered_files.add(parsed_name[0])
        unsuccessful_ordered_files = sorted(list(unsuccessful_ordered_files))

        successful = tracer.sort_locus_names(successful)
        unsuccessful = tracer.sort_locus_names(unsuccessful)

        for file in successful_ordered_files:
            success_out.write("{}\t{}\n".format(file, successful[file]))

        for file in unsuccessful_ordered_files:
            fail_out.write("{}\t{}\n".format(file, unsuccessful[file]))

        success_out.close()
        fail_out.close()

        #remove pointless .readcount files
        readcount_files = glob.glob("{}/aligned_reads/*.readcount".format(output_dir))
        for f in readcount_files:
            os.remove(f)

        if len(unsuccessful_directories) == 2:
            print "No successful Trinity assemblies"
            self.die_with_empty_cell(cell_name,  output_dir, species)



    def run_IgBlast(self, igblast, locus_names, output_dir, cell_name, index_location, ig_seqtype, should_resume):
        print  "##Running IgBLAST##"

        if should_resume:
            igblast_out_A = "{output_dir}/IgBLAST_output/{cell_name}_TCRA.IgBLASTOut".format(output_dir=output_dir, cell_name=cell_name)
            igblast_out_B = "{output_dir}/IgBLAST_output/{cell_name}_TCRB.IgBLASTOut".format(output_dir=output_dir, cell_name=cell_name)
            if (os.path.isfile(igblast_out_A) and os.path.getsize(igblast_out_A)>0) or (os.path.isfile(igblast_out_B) and os.path.getsize(igblast_out_B)>0):
                print "Resuming with existing IgBLAST output"
                return

        databases = {}
        for segment in ['v','d','j']:
            databases[segment] = "{}/imgt_tcr_db_{}.fa".format(index_location,segment)

        #lines below suppress Igblast warning about not having an auxliary file. Taken from http://stackoverflow.com/questions/11269575/how-to-hide-output-of-subprocess-in-python-2-7
        try:
            from subprocess import DEVNULL # py3k
        except ImportError:
            DEVNULL = open(os.devnull, 'wb')


        for locus in locus_names:
            print "##{}##".format(locus)
            trinity_fasta = "{}/Trinity_output/{}_{}.Trinity.fasta".format(output_dir, cell_name, locus)
            if os.path.isfile(trinity_fasta):
                command = [igblast, '-germline_db_V', databases['v'], '-germline_db_D', databases['d'], '-germline_db_J', databases['j'], '-domain_system', 'imgt', '-ig_seqtype', ig_seqtype, '-show_translation', '-num_alignments_V', '5', '-num_alignments_D', '5', '-num_alignments_J', '5', '-outfmt', '7', '-query', trinity_fasta]
                igblast_out = "{output_dir}/IgBLAST_output/{cell_name}_{locus}.IgBLASTOut".format(output_dir=output_dir, cell_name=cell_name, locus=locus)
                out = open(igblast_out, 'w')
                subprocess.check_call(command, stdout=out,stderr=DEVNULL)
                out.close()

        DEVNULL.close()



    def quantify_with_kallisto(self, kallisto, cell, output_dir, cell_name, kallisto_base_transcriptome, fastq1, fastq2, ncores, should_resume):
        print "##Running Kallisto##"
        if should_resume:
            if os.path.isfile("{}/expression_quantification/abundance.tsv".format(output_dir)):
                print "Resuming with existing Kallisto output"
                return

        print "##Making Kallisto indices##"
        kallisto_dirs = ['kallisto_index']
        for d in kallisto_dirs:
            tracer.makeOutputDir("{}/expression_quantification/{}".format(output_dir, d))
        fasta_filename = "{output_dir}/unfiltered_TCR_seqs/{cell_name}_TCRseqs.fa".format(output_dir=output_dir, cell_name=cell_name)
        fasta_file = open(fasta_filename, 'w')
        fasta_file.write(cell.get_fasta_string())
        fasta_file.close()

        output_transcriptome = "{}/expression_quantification/kallisto_index/{}_transcriptome.fa".format(output_dir, cell_name)
        with open(output_transcriptome, 'w') as outfile:
            for fname in [kallisto_base_transcriptome, fasta_filename]:
                with open(fname) as infile:
                    for line in infile:
                        outfile.write(line)

        idx_file = "{}/expression_quantification/kallisto_index/{}_transcriptome.idx".format(output_dir, cell_name)

        index_command = [kallisto, 'index', '-i', idx_file, output_transcriptome]
        subprocess.check_call(index_command)
        print "##Quantifying with Kallisto##"
        #### for multipe files in fastq1, seperated by ","
        fastq1_l=fastq1.split(",")
        fastq2_l=fastq2.split(",")
        n_file = len(fastq1_l)
        pair_l = [ (fastq1_l[i],fastq2_l[i]) for i in range(n_file)]
        pair_l = [ t for tt in pair_l for t in tt ]
        fastq1 = " ".join([ pair_l[i] for i in range(n_file)])
        fastq2 = " ".join([ pair_l[i+n_file] for i in range(n_file)])
        ###
        kallisto_command = [kallisto, 'quant', '-i', idx_file, '-t', ncores, '-o', "{}/expression_quantification".format(output_dir), fastq1, fastq2]
        print " ".join(kallisto_command)
        subprocess.check_call(kallisto_command)

        #delete index file because it's huge and unecessary. Delete transcriptome file
        #os.remove(idx_file)
        #os.remove(output_transcriptome)
        shutil.rmtree("{}/expression_quantification/kallisto_index/".format(output_dir))

    def print_cell_summary(self, cell, output_file):
        out_file = open(output_file, 'w')
        out_file.write('------------------\n{name}\n------------------\n'.format(name=cell.name))
        out_file.write('TCRA recombinants: {}\n'.format(cell.summarise_productivity('A')))
        out_file.write('TCRB recombinants: {}\n'.format(cell.summarise_productivity('B')))
        out_file.write('\n\n')
        out_file.write('#TCRA#\n')
        if cell.A_recombinants is None:
            out_file.write("No TCRA recombinants found\n\n")
        else:
            for rec in cell.A_recombinants:
                out_file.write(rec.get_summary())
                out_file.write("\n\n")
        out_file.write('#TCRB#\n')

        if cell.B_recombinants is None:
            out_file.write("No TCRB recombinants found\n\n")
        else:
            for rec in cell.B_recombinants:
                out_file.write(rec.get_summary())
                out_file.write("\n\n")
        out_file.close()

    def die_with_empty_cell(self, cell_name,  output_dir, species):
        print "##No TCR recombinants found##"
        #pdb.set_trace()
        cell = tracer.Cell(cell_name, None, None, None, None,  is_empty=True, species=species)
        self.print_cell_summary(cell, "{output_dir}/unfiltered_TCR_seqs/unfiltered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/unfiltered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))
        cell.filter_recombinants()
        self.print_cell_summary(cell, "{output_dir}/filtered_TCR_seqs/filtered_TCRs.txt".format(output_dir=output_dir))
        pickle.dump(cell, open("{output_dir}/filtered_TCR_seqs/{cell_name}.pkl".format(output_dir=output_dir, cell_name=cell.name), 'w'))
        exit(0)

##SUMMARISE

    def summarise(self):
        parser = argparse.ArgumentParser(description = "Summarise set of cells with reconstructed TCR sequences")
        parser.add_argument('--config_file', '-c', metavar="<CONFIG_FILE>", help='config file to use [tracer.conf]', default='tracer.conf')
        parser.add_argument('--use_unfiltered', '-u', help='use unfiltered recombinants', action="store_true")
        parser.add_argument('--keep_inkt', '-i', help='ignore iNKT cells when constructing networks', action="store_true")
        parser.add_argument('--graph_format', '-f', metavar="<GRAPH_FORMAT>", help='graphviz output format [pdf]', default='pdf')
        parser.add_argument('dir', metavar="<DIR>", help='directory containing subdirectories for each cell to be summarised')
        args = parser.parse_args(sys.argv[2:])

        root_dir = os.path.abspath(args.dir)
        graph_format = args.graph_format


        #Read config file
        config = ConfigParser.ConfigParser()
        config.read(args.config_file)

        dot = self.resolve_relative_path(config.get('tool_locations', 'dot_path'))
        neato = self.resolve_relative_path(config.get('tool_locations', 'neato_path'))

        #check that executables from config file can be used
        not_executable = []
        for name, x in {"dot":dot, "neato":neato}.iteritems():
            if not tracer.is_exe(x):
                not_executable.append((name, x))
        if len(not_executable) > 0:
            print
            print "Could not execute the following required tools. Check your configuration file."
            for t in not_executable:
                print t[0], t[1]
            print
            exit(1)

        cells = {}
        empty_cells = []
        NKT_cells = {}
        subdirectories = os.walk(root_dir).next()[1]

        if args.use_unfiltered:
            pkl_dir = "unfiltered_TCR_seqs"
            outdir = "{}/unfiltered_TCR_summary".format(root_dir)
            #outfile = open("{root_dir}/unfiltered_TCR_summary.txt".format(root_dir=root_dir), 'w')
            #length_filename_root = "{}/unfiltered_reconstructed_lengths_TCR".format(root_dir)

        else:
            pkl_dir = "filtered_TCR_seqs"
            outdir = "{}/filtered_TCR_summary".format(root_dir)
            #outfile = open("{root_dir}/filtered_TCR_summary.txt".format(root_dir=root_dir), 'w')
            #length_filename_root = "{}/filtered_reconstructed_lengths_TCR".format(root_dir)

        tracer.makeOutputDir(outdir)


        outfile = open("{}/TCR_summary.txt".format(outdir), 'w')
        length_filename_root = "{}/reconstructed_lengths_TCR".format(outdir)


        for d in subdirectories:
            cell_pkl = "{root_dir}/{d}/{pkl_dir}/{d}.pkl".format(pkl_dir=pkl_dir, d=d, root_dir=root_dir)
            if os.path.isfile(cell_pkl):
                cl = pickle.load(open(cell_pkl))
                cells[d] = cl
                if cl.is_empty:
                    empty_cells.append(d)
                if cl.is_inkt:
                    NKT_cells[d] = (cl.is_inkt, cl.getMainRecombinantIdentifiersForLocus('B'))
        count_of_cells_with_alpha_recovered = 0
        count_of_cells_with_beta_recovered = 0
        count_of_cells_with_paired_recovered = 0
        for cell_name, cell in cells.iteritems():
            prod_a_count = cell.count_productive_recombinants('A')
            prod_b_count = cell.count_productive_recombinants('B')
            if prod_a_count > 0:
                count_of_cells_with_alpha_recovered += 1
            if prod_b_count > 0:
                count_of_cells_with_beta_recovered += 1
            if prod_a_count > 0 and prod_b_count > 0:
                count_of_cells_with_paired_recovered += 1

        total_cells = len(cells)

        outfile.write("TCRA reconstruction:\t{count_of_cells_with_alpha_recovered} / {total_cells} ({alpha_percent}%)\nTCRB reconstruction:\t{count_of_cells_with_beta_recovered} / {total_cells} ({beta_percent}%)\nPaired productive chains\t{count_of_cells_with_paired_recovered} / {total_cells} ({paired_percent}%)\n\n".format(paired_percent=round((count_of_cells_with_paired_recovered/float(total_cells))*100,1), total_cells=total_cells, alpha_percent=round((count_of_cells_with_alpha_recovered/float(total_cells))*100,1), beta_percent=round((count_of_cells_with_beta_recovered/float(total_cells))*100,1), count_of_cells_with_beta_recovered=count_of_cells_with_beta_recovered, count_of_cells_with_paired_recovered=count_of_cells_with_paired_recovered, count_of_cells_with_alpha_recovered=count_of_cells_with_alpha_recovered))


        all_alpha_counter = Counter()
        all_beta_counter = Counter()
        prod_alpha_counter = Counter()
        prod_beta_count = Counter()

        counters = {'all_alpha':Counter(), 'all_beta':Counter(), 'prod_alpha':Counter(), 'prod_beta':Counter()}

        for cell in cells.values():
            counters['all_alpha'].update({cell.count_total_recombinants('A') : 1})
            counters['all_beta'].update({cell.count_total_recombinants('B') : 1})
            counters['prod_alpha'].update({cell.count_productive_recombinants('A') : 1})
            counters['prod_beta'].update({cell.count_productive_recombinants('B') : 1})

        max_recombinant_count = max(counters['all_alpha'].keys() + counters['all_beta'].keys())
        table_header = ['', '0 recombinants', '1 recombinant', '2 recombinants']
        recomb_range = range(0,3)
        if max_recombinant_count > 2:
            extra_header = [str(x) + " recombinants" for x in range(3, max_recombinant_count+1)]
            table_header = table_header + extra_header
            recomb_range = range(0, max_recombinant_count+1)

        t = PrettyTable(table_header)
        t.padding_width = 1
        t.align = "l"
        for label in ['all_alpha', 'all_beta', 'prod_alpha', 'prod_beta']:
            counter = counters[label]
            count_array = [counter[x] for x in recomb_range]
            total_with_at_least_one = sum(count_array[1:])
            percentages = ['']+[" ("+ str(round((float(x)/total_with_at_least_one)*100)) +"%)" for x in count_array[1:]]
            row = []
            for i in recomb_range:
                row.append(str(count_array[i]) + percentages[i])

            t.add_row([label] + row)
        outfile.write(t.get_string())


        #Reporting iNKT cells
        iNKT_count = len(NKT_cells)
        if iNKT_count == 1:
            cell_word = 'cell'
        else:
            cell_word = 'cells'
        outfile.write("\n\n#iNKT cells#\nFound {iNKT_count} iNKT {cell_word}\n".format(iNKT_count=iNKT_count, cell_word=cell_word))
        if iNKT_count >0:
            for cell_name, ids in NKT_cells.iteritems():
                outfile.write("###{cell_name}###\n".format(cell_name=cell_name))
                outfile.write("TCRA:\t{}\nTCRB\t{}\n\n".format(ids[0], ids[1]))

        #plot lengths of reconstructed sequences
        lengths = {'A':[], 'B':[]}
        for cell in cells.values():
            for locus in lengths.keys():
                lengths[locus] = lengths[locus] +  cell.get_trinity_lengths(locus)

        #plot TCRA length distributions
        plt.figure()
        plt.axvline(334, linestyle="--", color = 'k')
        plt.axvline(344, linestyle="--",color = 'k')
        sns.distplot(lengths['A'])
        sns.despine()
        plt.savefig("{}A.pdf".format(length_filename_root))

        #plot TCRB length distributions
        plt.figure()
        plt.axvline(339, linestyle="--", color = 'k')
        plt.axvline(345, linestyle="--",color = 'k')
        sns.distplot(lengths['B'])
        sns.despine()
        plt.savefig("{}B.pdf".format(length_filename_root))

        for cell_name in empty_cells:
            del cells[cell_name]

        if not args.keep_inkt:
            for cell_name in NKT_cells.keys():
                del cells[cell_name]

        #make clonotype networks
        #tracer.draw_network_from_cells(cells, outdir, graph_format, dot, neato)

        #plot clonotype sizes
        plt.figure()
        clonotype_sizes = tracer.get_component_groups_sizes(cells)
        w = 0.85
        x_range = range(1, len(clonotype_sizes) + 1)
        plt.bar(x_range, height=clonotype_sizes, width=w, color='black', align='center')
        plt.gca().set_xticks(x_range)
        plt.savefig("{}/clonotype_sizes.pdf".format(outdir))

    summarize = summarise

if __name__ == '__main__':
    Launcher()
